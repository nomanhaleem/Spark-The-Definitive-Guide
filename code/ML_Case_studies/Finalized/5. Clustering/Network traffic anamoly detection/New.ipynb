{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('app').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: timestamp, UnitPrice: double, CustomerID: double, Country: string, features: vector]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "va = VectorAssembler()\\\n",
    "  .setInputCols([\"Quantity\", \"UnitPrice\"])\\\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "sales = va.transform(spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"./../../../../../data/retail-data/by-day/*.csv\")\n",
    "  .limit(50)\n",
    "  .coalesce(1)\n",
    "  .where(\"Description IS NOT NULL\"))\n",
    "\n",
    "sales.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|   features|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|[48.0,1.79]|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|[20.0,1.25]|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|[24.0,1.65]|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|[24.0,1.25]|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom| [6.0,2.55]|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distanceMeasure: the distance measure. Supported options: 'euclidean' and 'cosine'. (default: euclidean)\n",
      "featuresCol: features column name. (default: features)\n",
      "initMode: The initialization algorithm. This can be either \"random\" to choose random points as initial cluster centers, or \"k-means||\" to use a parallel variant of k-means++ (default: k-means||)\n",
      "initSteps: The number of steps for k-means|| initialization mode. Must be > 0. (default: 2)\n",
      "k: The number of clusters to create. Must be > 1. (default: 2, current: 5)\n",
      "maxIter: max number of iterations (>= 0). (default: 20)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: -3274967362699018702)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.0001)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "km = KMeans().setK(5)\n",
    "print(km.explainParams())\n",
    "kmModel = km.fit(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans_d9847b6a6389"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 19, 2, 11, 8]\n",
      "Cluster Centers: \n",
      "[12.    0.93]\n",
      "[5.21052632 3.74105263]\n",
      "[48.    1.32]\n",
      "[24.36363636  0.94636364]\n",
      "[ 2.5     11.24375]\n"
     ]
    }
   ],
   "source": [
    "summary = kmModel.summary\n",
    "print(summary.clusterSizes) # number of points\n",
    "kmModel.computeCost(sales)\n",
    "centers = kmModel.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "bkm = BisectingKMeans().setK(5).setMaxIter(5)\n",
    "bkmModel = bkm.fit(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuresCol: features column name. (default: features)\n",
      "k: Number of independent Gaussians in the mixture model. Must be > 1. (default: 2, current: 5)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "seed: random seed. (default: 8948137684748870449)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.01)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "gmm = GaussianMixture().setK(5)\n",
    "print (gmm.explainParams())\n",
    "model = gmm.fit(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17364777675042192, 0.40868479342178, 0.03999996150661165, 0.1630798262595909, 0.21458764206159553]\n",
      "+--------------------+--------------------+\n",
      "|                mean|                 cov|\n",
      "+--------------------+--------------------+\n",
      "|[17.7721409197281...|41.05070949914583...|\n",
      "|[6.80376078272665...|10.89519357280599...|\n",
      "|[6.00000192468753...|4.00000000096711 ...|\n",
      "|[2.52439808609302...|0.770110579375161...|\n",
      "|[25.8245785761804...|168.5033578708051...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         4|\n",
      "|         1|\n",
      "|         4|\n",
      "|         2|\n",
      "|         4|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         0|\n",
      "|         0|\n",
      "|         4|\n",
      "|         4|\n",
      "|         1|\n",
      "|         1|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|         probability|\n",
      "+--------------------+\n",
      "|[8.36858831656477...|\n",
      "|[3.12247049269465...|\n",
      "|[3.46826975456394...|\n",
      "|[4.43116833348206...|\n",
      "|[6.53261456103164...|\n",
      "|[1.68584383362191...|\n",
      "|[5.08146041687457...|\n",
      "|[3.72629780544629...|\n",
      "|[7.37658166803052...|\n",
      "|[7.37658166803052...|\n",
      "|[2.25985055094103...|\n",
      "|[1.07988612154045...|\n",
      "|[0.00120683429194...|\n",
      "|[0.00120683429194...|\n",
      "|[0.84900646924519...|\n",
      "|[0.68925326121565...|\n",
      "|[8.72015493390864...|\n",
      "|[4.43116833348206...|\n",
      "|[7.37658166803052...|\n",
      "|[7.37658166803052...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = model.summary\n",
    "print(model.weights)\n",
    "model.gaussiansDF.show()\n",
    "summary.cluster.show()\n",
    "summary.clusterSizes\n",
    "summary.probability.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "tkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "tokenized = tkn.transform(sales.drop(\"features\"))\n",
    "cv = CountVectorizer()\\\n",
    "  .setInputCol(\"DescOut\")\\\n",
    "  .setOutputCol(\"features\")\\\n",
    "  .setVocabSize(500)\\\n",
    "  .setMinTF(0)\\\n",
    "  .setMinDF(0)\\\n",
    "  .setBinary(True)\n",
    "cvFitted = cv.fit(tokenized)\n",
    "prepped = cvFitted.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "docConcentration: Concentration parameter (commonly named \"alpha\") for the prior placed on documents' distributions over topics (\"theta\"). (undefined)\n",
      "featuresCol: features column name. (default: features)\n",
      "k: The number of topics (clusters) to infer. Must be > 1. (default: 10, current: 10)\n",
      "keepLastCheckpoint: (For EM optimizer) If using checkpointing, this indicates whether to keep the last checkpoint. If false, then the checkpoint will be deleted. Deleting the checkpoint can cause failures if a data partition is lost, so set this bit with care. (default: True)\n",
      "learningDecay: Learning rate, set as anexponential decay rate. This should be between (0.5, 1.0] to guarantee asymptotic convergence. (default: 0.51)\n",
      "learningOffset: A (positive) learning parameter that downweights early iterations. Larger values make early iterations count less (default: 1024.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 20, current: 5)\n",
      "optimizeDocConcentration: Indicates whether the docConcentration (Dirichlet parameter for document-topic distribution) will be optimized during training. (default: True)\n",
      "optimizer: Optimizer or inference algorithm used to estimate the LDA model.  Supported: online, em (default: online)\n",
      "seed: random seed. (default: -5312356916422951802)\n",
      "subsamplingRate: Fraction of the corpus to be sampled and used in each iteration of mini-batch gradient descent, in range (0, 1]. (default: 0.05)\n",
      "topicConcentration: Concentration parameter (commonly named \"beta\" or \"eta\") for the prior placed on topic' distributions over terms. (undefined)\n",
      "topicDistributionCol: Output column with estimates of the topic mixture distribution for each document (often called \"theta\" in the literature). Returns a vector of zeros for an empty document. (default: topicDistribution)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "lda = LDA().setK(10).setMaxIter(5)\n",
    "print (lda.explainParams())\n",
    "model = lda.fit(prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+--------------------+\n",
      "|topic|   termIndices|         termWeights|\n",
      "+-----+--------------+--------------------+\n",
      "|    0|[114, 63, 118]|[0.00943511328587...|\n",
      "|    1|  [49, 28, 56]|[0.00895179944471...|\n",
      "|    2| [12, 20, 111]|[0.01853200671111...|\n",
      "|    3|   [60, 8, 10]|[0.01187679234416...|\n",
      "|    4| [50, 110, 38]|[0.00994906941679...|\n",
      "|    5|   [30, 9, 66]|[0.01549615627022...|\n",
      "|    6| [79, 55, 136]|[0.01232558009687...|\n",
      "|    7|  [11, 5, 115]|[0.01794935152781...|\n",
      "|    8|    [2, 94, 4]|[0.01416778393951...|\n",
      "|    9|  [55, 35, 74]|[0.00877663282520...|\n",
      "+-----+--------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['water',\n",
       " 'hot',\n",
       " 'vintage',\n",
       " 'bottle',\n",
       " 'paperweight',\n",
       " '6',\n",
       " 'home',\n",
       " 'doormat',\n",
       " 'landmark',\n",
       " 'bicycle',\n",
       " 'frame',\n",
       " 'ribbons',\n",
       " '',\n",
       " 'classic',\n",
       " 'rose',\n",
       " 'kit',\n",
       " 'leaf',\n",
       " 'sweet',\n",
       " 'bag',\n",
       " 'airline',\n",
       " 'doorstop',\n",
       " 'light',\n",
       " 'in',\n",
       " 'christmas',\n",
       " 'heart',\n",
       " 'calm',\n",
       " 'set',\n",
       " 'keep',\n",
       " 'balloons',\n",
       " 'night',\n",
       " 'lights',\n",
       " '12',\n",
       " 'tin',\n",
       " 'english',\n",
       " 'caravan',\n",
       " 'stuff',\n",
       " 'tidy',\n",
       " 'oxford',\n",
       " 'full',\n",
       " 'cottage',\n",
       " 'notting',\n",
       " 'drawer',\n",
       " 'mushrooms',\n",
       " 'chrome',\n",
       " 'champion',\n",
       " 'amelie',\n",
       " 'mini',\n",
       " 'the',\n",
       " 'giant',\n",
       " 'design',\n",
       " 'elegant',\n",
       " 'tins',\n",
       " 'jet',\n",
       " 'fairy',\n",
       " \"50's\",\n",
       " 'holder',\n",
       " 'message',\n",
       " 'blue',\n",
       " 'storage',\n",
       " 'tier',\n",
       " 'covent',\n",
       " 'world',\n",
       " 'skulls',\n",
       " 'font',\n",
       " 'hearts',\n",
       " 'skull',\n",
       " 'clips',\n",
       " 'bell',\n",
       " 'red',\n",
       " 'party',\n",
       " 'chalkboard',\n",
       " 'save',\n",
       " '4',\n",
       " 'coloured',\n",
       " 'poppies',\n",
       " 'garden',\n",
       " 'nine',\n",
       " 'girl',\n",
       " 'shimmering',\n",
       " 'doughnut',\n",
       " 'dog',\n",
       " '3',\n",
       " 'tattoos',\n",
       " 'chilli',\n",
       " 'coat',\n",
       " 'torch',\n",
       " 'sunflower',\n",
       " 'tale',\n",
       " 'cards',\n",
       " 'puncture',\n",
       " 'woodland',\n",
       " 'bomb',\n",
       " 'knack',\n",
       " 'lip',\n",
       " 'collage',\n",
       " 'rabbit',\n",
       " 'sex',\n",
       " 'of',\n",
       " 'rack',\n",
       " 'wall',\n",
       " 'cracker',\n",
       " 'scottie',\n",
       " 'hill',\n",
       " 'led',\n",
       " 'black',\n",
       " 'art',\n",
       " 'envelopes',\n",
       " 'flytrap',\n",
       " 'box',\n",
       " 'pinks',\n",
       " 'camouflage',\n",
       " 'gingham',\n",
       " 'popcorn',\n",
       " 'with',\n",
       " 'knick',\n",
       " 'empire',\n",
       " 'grow',\n",
       " 'fancy',\n",
       " 'plate',\n",
       " 'natural',\n",
       " 'feltcraft',\n",
       " 'brown',\n",
       " 'paisley',\n",
       " 'repair',\n",
       " 'gumball',\n",
       " 'white',\n",
       " 'regency',\n",
       " 'cakestand',\n",
       " 'rocket',\n",
       " 'harmonica',\n",
       " 'a',\n",
       " 'or',\n",
       " 'transfer',\n",
       " 'street',\n",
       " 'planet',\n",
       " 'office',\n",
       " 'gloss',\n",
       " 'slate',\n",
       " 'towel',\n",
       " 'tea',\n",
       " 'breakfast']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.describeTopics(3).show()\n",
    "cvFitted.vocabulary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark_2_4_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
