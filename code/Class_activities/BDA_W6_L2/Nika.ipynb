{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/26 13:04:50 WARN Utils: Your hostname, Nikas-Macbook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.72.3.173 instead (on interface en0)\n",
      "24/05/26 13:04:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/26 13:04:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# initializing the Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+------+\n",
      "|age|sex|chest pain type|resting bp s|cholesterol|fasting blood sugar|resting ecg|max heart rate|exercise angina|oldpeak|ST slope|target|\n",
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+------+\n",
      "| 42|  1|              3|         134|        240|                  0|          0|           160|              0|    0.0|       1|     0|\n",
      "| 54|  0|              3|         110|        214|                  0|          0|           158|              0|    1.6|       2|     0|\n",
      "| 46|  1|              1|         140|        272|                  1|          0|           175|              0|    2.0|       2|     1|\n",
      "| 29|  1|              2|         130|        204|                  0|          2|           202|              0|    0.0|       1|     0|\n",
      "| 52|  1|              1|         152|        298|                  1|          0|           178|              0|    1.2|       2|     0|\n",
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "df = spark.read.csv(\"heart_statlog_cleveland_hungary_final.csv\", inferSchema = True, header=True)\n",
    "df = df.repartition(10)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- chest pain type: integer (nullable = true)\n",
      " |-- resting bp s: integer (nullable = true)\n",
      " |-- cholesterol: integer (nullable = true)\n",
      " |-- fasting blood sugar: integer (nullable = true)\n",
      " |-- resting ecg: integer (nullable = true)\n",
      " |-- max heart rate: integer (nullable = true)\n",
      " |-- exercise angina: integer (nullable = true)\n",
      " |-- oldpeak: double (nullable = true)\n",
      " |-- ST slope: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View data types\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(train_data.count())\n",
    "print(test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, PCA\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the feature vectors\n",
    "assembler = VectorAssembler(inputCols=['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol', 'fasting blood sugar', 'resting ecg', 'max heart rate', 'exercise angina', 'oldpeak', 'ST slope'], outputCol='features')\n",
    "\n",
    "# Transform the data\n",
    "trainData = assembler.transform(train_data)\n",
    "testData = assembler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Logistic Regression estimator\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='target', maxIter=100)\n",
    "\n",
    "# Define the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='target')\n",
    "\n",
    "# Define the cross-validator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Fit the cross-validator and get the best model\n",
    "cvModel = cv.fit(trainData)\n",
    "bestLRModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC:  0.9051517406764238\n"
     ]
    }
   ],
   "source": [
    "lrPredictions = bestLRModel.transform(testData)\n",
    "lrAccuracy = evaluator.evaluate(lrPredictions, {evaluator.metricName: 'areaUnderROC'})\n",
    "print('Logistic Regression AUC: ', lrAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 14:18:41 WARN DAGScheduler: Broadcasting large task binary with size 1068.8 KiB\n",
      "24/05/23 14:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1078.8 KiB\n",
      "24/05/23 14:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1394.7 KiB\n",
      "24/05/23 14:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1655.6 KiB\n",
      "24/05/23 14:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1848.6 KiB\n",
      "24/05/23 14:18:45 WARN DAGScheduler: Broadcasting large task binary with size 1370.2 KiB\n",
      "24/05/23 14:18:48 WARN DAGScheduler: Broadcasting large task binary with size 1411.6 KiB\n",
      "24/05/23 14:18:48 WARN DAGScheduler: Broadcasting large task binary with size 2025.7 KiB\n",
      "24/05/23 14:18:49 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:18:49 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:18:49 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:18:50 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/05/23 14:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1015.4 KiB\n",
      "24/05/23 14:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1078.8 KiB\n",
      "24/05/23 14:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1394.7 KiB\n",
      "24/05/23 14:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1655.6 KiB\n",
      "24/05/23 14:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1848.6 KiB\n",
      "24/05/23 14:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1952.5 KiB\n",
      "24/05/23 14:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1618.5 KiB\n",
      "24/05/23 14:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1013.9 KiB\n",
      "24/05/23 14:18:57 WARN DAGScheduler: Broadcasting large task binary with size 1476.1 KiB\n",
      "24/05/23 14:18:59 WARN DAGScheduler: Broadcasting large task binary with size 1411.6 KiB\n",
      "24/05/23 14:18:59 WARN DAGScheduler: Broadcasting large task binary with size 2025.7 KiB\n",
      "24/05/23 14:19:00 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:00 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:19:00 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:19:00 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:19:01 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:19:01 WARN DAGScheduler: Broadcasting large task binary with size 1390.0 KiB\n",
      "24/05/23 14:19:02 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:19:07 WARN DAGScheduler: Broadcasting large task binary with size 1070.3 KiB\n",
      "24/05/23 14:19:10 WARN DAGScheduler: Broadcasting large task binary with size 1095.4 KiB\n",
      "24/05/23 14:19:10 WARN DAGScheduler: Broadcasting large task binary with size 1411.0 KiB\n",
      "24/05/23 14:19:10 WARN DAGScheduler: Broadcasting large task binary with size 1664.9 KiB\n",
      "24/05/23 14:19:10 WARN DAGScheduler: Broadcasting large task binary with size 1842.9 KiB\n",
      "24/05/23 14:19:11 WARN DAGScheduler: Broadcasting large task binary with size 1370.8 KiB\n",
      "24/05/23 14:19:12 WARN DAGScheduler: Broadcasting large task binary with size 1423.8 KiB\n",
      "24/05/23 14:19:12 WARN DAGScheduler: Broadcasting large task binary with size 2040.7 KiB\n",
      "24/05/23 14:19:12 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:13 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:19:13 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:19:14 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/05/23 14:19:18 WARN DAGScheduler: Broadcasting large task binary with size 1095.4 KiB\n",
      "24/05/23 14:19:19 WARN DAGScheduler: Broadcasting large task binary with size 1411.0 KiB\n",
      "24/05/23 14:19:19 WARN DAGScheduler: Broadcasting large task binary with size 1664.9 KiB\n",
      "24/05/23 14:19:19 WARN DAGScheduler: Broadcasting large task binary with size 1842.9 KiB\n",
      "24/05/23 14:19:19 WARN DAGScheduler: Broadcasting large task binary with size 1790.4 KiB\n",
      "24/05/23 14:19:19 WARN DAGScheduler: Broadcasting large task binary with size 1433.8 KiB\n",
      "24/05/23 14:19:20 WARN DAGScheduler: Broadcasting large task binary with size 1458.5 KiB\n",
      "24/05/23 14:19:21 WARN DAGScheduler: Broadcasting large task binary with size 1423.8 KiB\n",
      "24/05/23 14:19:21 WARN DAGScheduler: Broadcasting large task binary with size 2040.7 KiB\n",
      "24/05/23 14:19:22 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:22 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:19:22 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:19:22 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "24/05/23 14:19:23 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:23 WARN DAGScheduler: Broadcasting large task binary with size 1483.4 KiB\n",
      "24/05/23 14:19:24 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:19:29 WARN DAGScheduler: Broadcasting large task binary with size 1072.1 KiB\n",
      "24/05/23 14:19:31 WARN DAGScheduler: Broadcasting large task binary with size 1102.7 KiB\n",
      "24/05/23 14:19:32 WARN DAGScheduler: Broadcasting large task binary with size 1427.1 KiB\n",
      "24/05/23 14:19:32 WARN DAGScheduler: Broadcasting large task binary with size 1685.0 KiB\n",
      "24/05/23 14:19:32 WARN DAGScheduler: Broadcasting large task binary with size 1825.4 KiB\n",
      "24/05/23 14:19:32 WARN DAGScheduler: Broadcasting large task binary with size 1379.5 KiB\n",
      "24/05/23 14:19:34 WARN DAGScheduler: Broadcasting large task binary with size 1428.8 KiB\n",
      "24/05/23 14:19:34 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/23 14:19:34 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:34 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:19:35 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/05/23 14:19:35 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:38 WARN DAGScheduler: Broadcasting large task binary with size 1102.7 KiB\n",
      "24/05/23 14:19:38 WARN DAGScheduler: Broadcasting large task binary with size 1427.1 KiB\n",
      "24/05/23 14:19:39 WARN DAGScheduler: Broadcasting large task binary with size 1685.0 KiB\n",
      "24/05/23 14:19:39 WARN DAGScheduler: Broadcasting large task binary with size 1825.4 KiB\n",
      "24/05/23 14:19:39 WARN DAGScheduler: Broadcasting large task binary with size 1712.6 KiB\n",
      "24/05/23 14:19:39 WARN DAGScheduler: Broadcasting large task binary with size 1342.6 KiB\n",
      "24/05/23 14:19:40 WARN DAGScheduler: Broadcasting large task binary with size 1462.1 KiB\n",
      "24/05/23 14:19:41 WARN DAGScheduler: Broadcasting large task binary with size 1428.8 KiB\n",
      "24/05/23 14:19:42 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/23 14:19:42 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:43 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:19:43 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/05/23 14:19:43 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:19:44 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:44 WARN DAGScheduler: Broadcasting large task binary with size 1296.7 KiB\n",
      "24/05/23 14:19:44 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:19:49 WARN DAGScheduler: Broadcasting large task binary with size 1064.0 KiB\n",
      "24/05/23 14:19:51 WARN DAGScheduler: Broadcasting large task binary with size 1092.2 KiB\n",
      "24/05/23 14:19:51 WARN DAGScheduler: Broadcasting large task binary with size 1414.4 KiB\n",
      "24/05/23 14:19:52 WARN DAGScheduler: Broadcasting large task binary with size 1675.2 KiB\n",
      "24/05/23 14:19:52 WARN DAGScheduler: Broadcasting large task binary with size 1865.3 KiB\n",
      "24/05/23 14:19:53 WARN DAGScheduler: Broadcasting large task binary with size 1381.2 KiB\n",
      "24/05/23 14:19:54 WARN DAGScheduler: Broadcasting large task binary with size 1404.5 KiB\n",
      "24/05/23 14:19:55 WARN DAGScheduler: Broadcasting large task binary with size 2018.0 KiB\n",
      "24/05/23 14:19:55 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:19:55 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:19:55 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:19:56 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/05/23 14:19:59 WARN DAGScheduler: Broadcasting large task binary with size 1092.2 KiB\n",
      "24/05/23 14:19:59 WARN DAGScheduler: Broadcasting large task binary with size 1414.4 KiB\n",
      "24/05/23 14:20:00 WARN DAGScheduler: Broadcasting large task binary with size 1675.2 KiB\n",
      "24/05/23 14:20:00 WARN DAGScheduler: Broadcasting large task binary with size 1865.3 KiB\n",
      "24/05/23 14:20:00 WARN DAGScheduler: Broadcasting large task binary with size 1890.2 KiB\n",
      "24/05/23 14:20:00 WARN DAGScheduler: Broadcasting large task binary with size 1452.9 KiB\n",
      "24/05/23 14:20:01 WARN DAGScheduler: Broadcasting large task binary with size 1476.5 KiB\n",
      "24/05/23 14:20:02 WARN DAGScheduler: Broadcasting large task binary with size 1404.5 KiB\n",
      "24/05/23 14:20:02 WARN DAGScheduler: Broadcasting large task binary with size 2018.0 KiB\n",
      "24/05/23 14:20:03 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:20:03 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:20:04 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:20:04 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/23 14:20:04 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:20:04 WARN DAGScheduler: Broadcasting large task binary with size 1805.6 KiB\n",
      "24/05/23 14:20:04 WARN DAGScheduler: Broadcasting large task binary with size 1013.1 KiB\n",
      "24/05/23 14:20:05 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:20:10 WARN DAGScheduler: Broadcasting large task binary with size 1062.0 KiB\n",
      "24/05/23 14:20:12 WARN DAGScheduler: Broadcasting large task binary with size 1104.1 KiB\n",
      "24/05/23 14:20:13 WARN DAGScheduler: Broadcasting large task binary with size 1427.7 KiB\n",
      "24/05/23 14:20:13 WARN DAGScheduler: Broadcasting large task binary with size 1687.7 KiB\n",
      "24/05/23 14:20:13 WARN DAGScheduler: Broadcasting large task binary with size 1871.5 KiB\n",
      "24/05/23 14:20:13 WARN DAGScheduler: Broadcasting large task binary with size 1383.6 KiB\n",
      "24/05/23 14:20:14 WARN DAGScheduler: Broadcasting large task binary with size 1419.4 KiB\n",
      "24/05/23 14:20:15 WARN DAGScheduler: Broadcasting large task binary with size 2047.3 KiB\n",
      "24/05/23 14:20:15 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:20:15 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:20:15 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/05/23 14:20:17 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:20:19 WARN DAGScheduler: Broadcasting large task binary with size 1014.6 KiB\n",
      "24/05/23 14:20:21 WARN DAGScheduler: Broadcasting large task binary with size 1104.1 KiB\n",
      "24/05/23 14:20:21 WARN DAGScheduler: Broadcasting large task binary with size 1427.7 KiB\n",
      "24/05/23 14:20:21 WARN DAGScheduler: Broadcasting large task binary with size 1687.7 KiB\n",
      "24/05/23 14:20:21 WARN DAGScheduler: Broadcasting large task binary with size 1871.5 KiB\n",
      "24/05/23 14:20:21 WARN DAGScheduler: Broadcasting large task binary with size 1833.3 KiB\n",
      "24/05/23 14:20:21 WARN DAGScheduler: Broadcasting large task binary with size 1361.8 KiB\n",
      "24/05/23 14:20:22 WARN DAGScheduler: Broadcasting large task binary with size 1482.5 KiB\n",
      "24/05/23 14:20:23 WARN DAGScheduler: Broadcasting large task binary with size 1419.4 KiB\n",
      "24/05/23 14:20:23 WARN DAGScheduler: Broadcasting large task binary with size 2047.3 KiB\n",
      "24/05/23 14:20:24 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/23 14:20:24 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/23 14:20:24 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/05/23 14:20:24 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/05/23 14:20:25 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:20:25 WARN DAGScheduler: Broadcasting large task binary with size 1717.2 KiB\n",
      "24/05/23 14:20:25 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/23 14:20:27 WARN DAGScheduler: Broadcasting large task binary with size 1153.3 KiB\n",
      "24/05/23 14:20:28 WARN DAGScheduler: Broadcasting large task binary with size 1530.3 KiB\n",
      "24/05/23 14:20:28 WARN DAGScheduler: Broadcasting large task binary with size 1859.5 KiB\n",
      "24/05/23 14:20:28 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/05/23 14:20:28 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/23 14:20:28 WARN DAGScheduler: Broadcasting large task binary with size 2022.9 KiB\n",
      "24/05/23 14:20:28 WARN DAGScheduler: Broadcasting large task binary with size 1418.0 KiB\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest estimator\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='target')\n",
    "\n",
    "# Define the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 20]) \\\n",
    "    .addGrid(rf.numTrees, [50, 100, 200]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='target')\n",
    "\n",
    "# Define the cross-validator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Fit the cross-validator and get the best model\n",
    "cvModel = cv.fit(trainData)\n",
    "bestRFModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 14:20:52 WARN DAGScheduler: Broadcasting large task binary with size 1681.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC:  0.936620644312952\n"
     ]
    }
   ],
   "source": [
    "rfPredictions = bestRFModel.transform(testData)\n",
    "rfAccuracy = evaluator.evaluate(rfPredictions, {evaluator.metricName: 'areaUnderROC'})\n",
    "print('Random Forest AUC: ', rfAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/26 13:10:47 WARN CacheManager: Asked to cache already cached data.        \n",
      "24/05/26 13:10:47 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM AUC:  0.8843523997370152\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM estimator\n",
    "svm = LinearSVC(featuresCol='features', labelCol='target', maxIter=100)\n",
    "\n",
    "# Define the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='target')\n",
    "\n",
    "# Define the cross-validator\n",
    "cv = CrossValidator(estimator=svm, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Fit the cross-validator and get the best model\n",
    "cvModel = cv.fit(trainData)\n",
    "bestSVMModel = cvModel.bestModel\n",
    "\n",
    "# Make predictions on the test data using the best SVM model\n",
    "svmPredictions = bestSVMModel.transform(testData)\n",
    "svmAccuracy = evaluator.evaluate(svmPredictions, {evaluator.metricName: 'areaUnderROC'})\n",
    "print('SVM AUC: ', svmAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The best model: Random Forests\n",
    "\n",
    "The accuracy: 93.7%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
