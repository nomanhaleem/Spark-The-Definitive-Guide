{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/29 12:08:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .load(\"/Users/d.c.deh./Documents/Visual Studio/Data science 2/Csv files/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              review|           sentiment|\n",
      "+--------------------+--------------------+\n",
      "|One of the other ...|            positive|\n",
      "|\"A wonderful litt...| not only is it w...|\n",
      "|\"I thought this w...| but spirited you...|\n",
      "|Basically there's...|            negative|\n",
      "|\"Petter Mattei's ...| power and succes...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There are comma's in the reviews, so I have to clean this up a bit because currently it puts part of the reviews in the sentiment column\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I take out the rows where the review is also partly in the sentiment column. There is probably a better way to do this without dropping these rows.\n",
    "filtered_df = df.filter((df.sentiment == \"positive\") | (df.sentiment == \"negative\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              review|sentiment|\n",
      "+--------------------+---------+\n",
      "|One of the other ...| positive|\n",
      "|Basically there's...| negative|\n",
      "|I sure would like...| positive|\n",
      "|This show was an ...| negative|\n",
      "|Encouraged by the...| negative|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reworking the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "\n",
    "# Defining a tokenizer\n",
    "tokenizer = Tokenizer(inputCol = \"review\", outputCol = \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the tokenizer to the dataframe\n",
    "splitted_review = tokenizer.transform(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Removing the stop words\n",
    "remover = StopWordsRemover(inputCol = \"words\", outputCol = \"filtered review\")\n",
    "no_stop_words_df = remover.transform(splitted_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+\n",
      "|              review|sentiment|               words|     filtered review|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|One of the other ...| positive|[one, of, the, ot...|[one, reviewers, ...|\n",
      "|Basically there's...| negative|[basically, there...|[basically, famil...|\n",
      "|I sure would like...| positive|[i, sure, would, ...|[sure, like, see,...|\n",
      "|This show was an ...| negative|[this, show, was,...|[show, amazing,, ...|\n",
      "|Encouraged by the...| negative|[encouraged, by, ...|[encouraged, posi...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_stop_words_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "\n",
    "# Changing the text to numbers\n",
    "hashing = HashingTF(inputCol = \"filtered review\", outputCol = \"hashed review\")\n",
    "transformed_df = hashing.transform(no_stop_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|              review|sentiment|               words|     filtered review|       hashed review|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|One of the other ...| positive|[one, of, the, ot...|[one, reviewers, ...|(262144,[3280,436...|\n",
      "|Basically there's...| negative|[basically, there...|[basically, famil...|(262144,[6512,853...|\n",
      "|I sure would like...| positive|[i, sure, would, ...|[sure, like, see,...|(262144,[1889,545...|\n",
      "|This show was an ...| negative|[this, show, was,...|[show, amazing,, ...|(262144,[2437,825...|\n",
      "|Encouraged by the...| negative|[encouraged, by, ...|[encouraged, posi...|(262144,[8538,149...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Changing the sentiment to binary values\n",
    "binary_df = transformed_df.withColumn(\"rating\", when (transformed_df.sentiment == \"positive\", 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+------+\n",
      "|              review|sentiment|               words|     filtered review|       hashed review|rating|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+------+\n",
      "|One of the other ...| positive|[one, of, the, ot...|[one, reviewers, ...|(262144,[3280,436...|     1|\n",
      "|Basically there's...| negative|[basically, there...|[basically, famil...|(262144,[6512,853...|     0|\n",
      "|I sure would like...| positive|[i, sure, would, ...|[sure, like, see,...|(262144,[1889,545...|     1|\n",
      "|This show was an ...| negative|[this, show, was,...|[show, amazing,, ...|(262144,[2437,825...|     0|\n",
      "|Encouraged by the...| negative|[encouraged, by, ...|[encouraged, posi...|(262144,[8538,149...|     0|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the relevant columns\n",
    "prepared_df = binary_df[\"rating\", \"hashed review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|rating|       hashed review|\n",
      "+------+--------------------+\n",
      "|     1|(262144,[3280,436...|\n",
      "|     0|(262144,[6512,853...|\n",
      "|     1|(262144,[1889,545...|\n",
      "|     0|(262144,[2437,825...|\n",
      "|     0|(262144,[8538,149...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = prepared_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/29 12:08:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/29 12:08:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/29 12:08:54 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Defining the model\n",
    "lr = LogisticRegression(featuresCol = \"hashed review\", labelCol = \"rating\", maxIter=10)\n",
    "\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/29 12:08:59 WARN DAGScheduler: Broadcasting large task binary with size 1602.9 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(rating=0, hashed review=SparseVector(262144, {19: 1.0, 3926: 1.0, 5297: 1.0, 7629: 1.0, 15775: 1.0, 15965: 1.0, 17252: 1.0, 17291: 1.0, 20236: 1.0, 21534: 1.0, 25629: 2.0, 26844: 1.0, 34343: 1.0, 41095: 1.0, 43890: 1.0, 51007: 3.0, 51471: 1.0, 51678: 1.0, 52366: 1.0, 52471: 1.0, 53651: 1.0, 58074: 1.0, 58227: 1.0, 68821: 2.0, 70152: 1.0, 81916: 1.0, 84025: 1.0, 84738: 1.0, 87405: 1.0, 87419: 1.0, 93757: 1.0, 93803: 1.0, 95513: 1.0, 95685: 1.0, 96984: 1.0, 98431: 1.0, 100694: 1.0, 100869: 1.0, 105448: 1.0, 113432: 1.0, 115002: 1.0, 120228: 1.0, 123874: 1.0, 124786: 1.0, 133243: 1.0, 134032: 1.0, 134685: 1.0, 137733: 1.0, 141037: 1.0, 144803: 1.0, 146027: 1.0, 148880: 1.0, 150892: 1.0, 153078: 1.0, 153169: 1.0, 158102: 1.0, 158661: 1.0, 164964: 1.0, 166377: 1.0, 171368: 1.0, 175786: 1.0, 185450: 1.0, 186635: 1.0, 186925: 1.0, 188835: 1.0, 191174: 1.0, 191458: 1.0, 191515: 1.0, 192450: 1.0, 197438: 1.0, 202721: 1.0, 203895: 1.0, 207842: 1.0, 211154: 1.0, 214676: 1.0, 219879: 1.0, 221552: 1.0, 224909: 1.0, 235375: 2.0, 240187: 1.0, 242022: 1.0, 248248: 1.0, 250580: 1.0, 256035: 1.0, 256468: 1.0, 257342: 1.0, 260499: 1.0}), rawPrediction=DenseVector([2.1244, -2.1244]), probability=DenseVector([0.8933, 0.1067]), prediction=0.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/29 12:09:22 WARN DAGScheduler: Broadcasting large task binary with size 1601.4 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8494936561517867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Defining an evaluator for the model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"accuracy\")\n",
    "\n",
    "# Using the evaluator to compute the accuracy\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other models won't work, ALS requires 3 columns and the decision tree or random forest gives an error because the calculations are too large for the processor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Databases_Big_Data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
